{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to build neural networks\n",
    "\n",
    "#### Working from keras documentation (https://keras.io/) and also this blog post.... https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "import keras.utils as k_utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc1dba9a1d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset is 3D, so it will need to be flattened\n",
    "pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize so all the values line between 0-1\n",
    "X_train /= 255\n",
    "X_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target is currently still a list on integers, but it needs to be categories, can do this using utils.to_category\n",
    "y_train = k_utils.to_categorical(y_train)\n",
    "y_test = k_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple multi-layer perceptron model\n",
    "#### The model is build sequentially, with layers added one at a time. We're only adding one hidden layer and an output layer for this first simple model, but we'll be adding more layers later\n",
    "#### input_dims is the input dimensions, this only needs to be secified in the first layer\n",
    "#### finding the best network topology for your needs usually comes down to a little trial and error, but you need a large enough netwrok to capture the structure of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can now create a baseline model\n",
    "\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = pixels, input_dim=pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units = num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The baseline model has one hidden layer. The hidden layer has the same number of neurons as there are inputs (28*28 pixels).\n",
    "#### The Dense() class defines fully connected layers\n",
    "#### The softmax activation function for the output layer output a probability value, so one of the classes (0-9) will be selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.2775 - acc: 0.9212 - val_loss: 0.1418 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.1094 - acc: 0.9684 - val_loss: 0.0938 - val_acc: 0.9714\n",
      "Epoch 3/10\n",
      " - 5s - loss: 0.0716 - acc: 0.9788 - val_loss: 0.0783 - val_acc: 0.9771\n",
      "Epoch 4/10\n",
      " - 5s - loss: 0.0493 - acc: 0.9860 - val_loss: 0.0674 - val_acc: 0.9798\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0358 - acc: 0.9897 - val_loss: 0.0646 - val_acc: 0.9794\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0260 - acc: 0.9930 - val_loss: 0.0596 - val_acc: 0.9812\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0192 - acc: 0.9954 - val_loss: 0.0631 - val_acc: 0.9813\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0153 - acc: 0.9962 - val_loss: 0.0573 - val_acc: 0.9812\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0105 - acc: 0.9979 - val_loss: 0.0568 - val_acc: 0.9828\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0074 - acc: 0.9988 - val_loss: 0.0663 - val_acc: 0.9798\n",
      "Baseline Error: 2.02%\n"
     ]
    }
   ],
   "source": [
    "# build the baseline model\n",
    "model = baseline_model()\n",
    "\n",
    "# Fit the model, over 10 epochs, with update every 200 images\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Evaluate baseline model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epochs refers to the number of iteractions through the dataset for the training process. And the batch_size sets the number of instances that are evaluated before the network weights are updated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a CNN\n",
    "#### This requires slightly different reshaping compared to the previous example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "#and normalize\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = k_utils.to_categorical(y_train)\n",
    "y_test = k_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv2D() - 2D convolutional layer (for spatial convolution over images) filters is the dimensionality of the output space, kernel size is the width and height of the 2D convolution window (must be an odd integer), need to define the input shape for the first layer, need to define the activaton function\n",
    "#### MaxPooling2D() is used to reduce the spatial dimensions of the output volumne\n",
    "#### Dropout() helps with overfitting, sets a random fraction of the input units to 0 at each update during training. Form of regularization. \n",
    "#### Flatten() flattens the input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to build model\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 32,kernel_size = (5,5), input_shape = (1,28,28), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 128, activation = 'relu'))\n",
    "    model.add(Dense(units = num_classes, activation = 'softmax'))\n",
    "    \n",
    "    #compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 27s - loss: 0.2390 - acc: 0.9321 - val_loss: 0.0735 - val_acc: 0.9769\n",
      "Epoch 2/10\n",
      " - 25s - loss: 0.0695 - acc: 0.9798 - val_loss: 0.0484 - val_acc: 0.9850\n",
      "Epoch 3/10\n",
      " - 26s - loss: 0.0496 - acc: 0.9849 - val_loss: 0.0437 - val_acc: 0.9862\n",
      "Epoch 4/10\n",
      " - 26s - loss: 0.0391 - acc: 0.9876 - val_loss: 0.0396 - val_acc: 0.9870\n",
      "Epoch 5/10\n",
      " - 26s - loss: 0.0312 - acc: 0.9905 - val_loss: 0.0350 - val_acc: 0.9878\n",
      "Epoch 6/10\n",
      " - 25s - loss: 0.0266 - acc: 0.9914 - val_loss: 0.0354 - val_acc: 0.9875\n",
      "Epoch 7/10\n",
      " - 26s - loss: 0.0217 - acc: 0.9932 - val_loss: 0.0350 - val_acc: 0.9892\n",
      "Epoch 8/10\n",
      " - 25s - loss: 0.0181 - acc: 0.9943 - val_loss: 0.0363 - val_acc: 0.9881\n",
      "Epoch 9/10\n",
      " - 25s - loss: 0.0153 - acc: 0.9956 - val_loss: 0.0410 - val_acc: 0.9886\n",
      "Epoch 10/10\n",
      " - 26s - loss: 0.0136 - acc: 0.9957 - val_loss: 0.0383 - val_acc: 0.9897\n",
      "CNN Error: 1.03%\n"
     ]
    }
   ],
   "source": [
    "#build the actual model\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "#fit the model, over 10 epochs, with update every 200 images\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10, batch_size = 200, verbose = 2)\n",
    "\n",
    "#evaluate model\n",
    "scores = model.evaluate(X_test,y_test, verbose = 0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our error rate has dropped to 1.03% with a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a larger CNN for classification with the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to build bigger model\n",
    "\n",
    "def large_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 32,kernel_size = (5,5), input_shape = (1,28,28), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (5,5), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 128, activation = 'relu'))\n",
    "    model.add(Dense(units = 50, activation = 'relu'))\n",
    "    model.add(Dense(units = num_classes, activation = 'softmax'))\n",
    "    \n",
    "    #compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 38s 641us/step - loss: 0.2915 - acc: 0.9090 - val_loss: 0.0646 - val_acc: 0.9801\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 36s 605us/step - loss: 0.0713 - acc: 0.9776 - val_loss: 0.0421 - val_acc: 0.9853\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 37s 616us/step - loss: 0.0500 - acc: 0.9839 - val_loss: 0.0388 - val_acc: 0.9880\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 37s 615us/step - loss: 0.0389 - acc: 0.9878 - val_loss: 0.0252 - val_acc: 0.9917\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 41s 679us/step - loss: 0.0317 - acc: 0.9900 - val_loss: 0.0286 - val_acc: 0.9906\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 40s 667us/step - loss: 0.0283 - acc: 0.9909 - val_loss: 0.0252 - val_acc: 0.9916\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 39s 642us/step - loss: 0.0237 - acc: 0.9923 - val_loss: 0.0255 - val_acc: 0.9918\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 39s 646us/step - loss: 0.0206 - acc: 0.9931 - val_loss: 0.0217 - val_acc: 0.9935\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 39s 654us/step - loss: 0.0197 - acc: 0.9932 - val_loss: 0.0256 - val_acc: 0.9924\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 39s 651us/step - loss: 0.0188 - acc: 0.9942 - val_loss: 0.0218 - val_acc: 0.9936\n",
      "Large CNN model error: 0.64%\n"
     ]
    }
   ],
   "source": [
    "#build model\n",
    "model = large_cnn()\n",
    "\n",
    "#fit model, over 10 epochs, with update ever 200 images (batch szie = 200)\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10, batch_size = 200)\n",
    "\n",
    "#evaluate model\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Large CNN model error: %.2f%%' % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further improvement with this 'closer to state of the art' model. Error rate has dropped to 0.64%. Took a little longer to train, but nothing too bad, although small dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
