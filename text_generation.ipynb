{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras and TF to build an LSTM\n",
    "\n",
    "### Text generation from Macbeth.txt file. Example from https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"macbeth.txt\"\n",
    "\n",
    "text = (open(filename).read()).lower()\n",
    "\n",
    "# mapping characters with integers\n",
    "unique_chars = sorted(list(set(text)))\n",
    "\n",
    "#create empty dictionaries\n",
    "char_to_int = {}\n",
    "int_to_char = {}\n",
    "\n",
    "#creating character to integer mappings\n",
    "for i, c in enumerate (unique_chars):\n",
    "    char_to_int.update({c: i})\n",
    "    int_to_char.update({i: c})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing input and output dataset\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# working with chunks of 50 characters. Use the first 49 characters to train on, and the 50th as the labelA\n",
    "for i in range(0, len(text) - 50, 1):\n",
    "    sequence = text[i:i + 50]\n",
    "    label =text[i + 50]\n",
    "    X.append([char_to_int[char] for char in sequence])\n",
    "    Y.append(char_to_int[label])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A LSTM network expects the input to be in the form [samples, time steps, features] where samples is the number of data points we have, time steps is the number of time-dependent steps that are there in a single data point, features refers to the number of variables we have for the corresponding true value in Y. We then scale the values in X_modified between 0 to 1 and one hot encode our true values in Y_modified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping, normalizing and one hot encoding\n",
    "X_modified = np.reshape(X, (len(X), 50, 1))\n",
    "X_modified = X_modified / float(len(unique_chars))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units = 300, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(LSTM(units = 300))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Dense(units = Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 50, 300)           362400    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 43)                12943     \n",
      "=================================================================\n",
      "Total params: 1,096,543\n",
      "Trainable params: 1,096,543\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100271/100271 [==============================] - 697s 7ms/step - loss: 2.7484\n",
      "Epoch 2/2\n",
      "100271/100271 [==============================] - 740s 7ms/step - loss: 2.4903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b4c50eda0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model\n",
    "model.fit(X_modified, Y_modified, epochs=2, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m\n",
      "a\n",
      "c\n",
      "d\n",
      ".\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "e\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "h\n",
      "e\n",
      "e\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "h\n",
      "e\n",
      "e\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "h\n"
     ]
    }
   ],
   "source": [
    "# picking a random seed\n",
    "start_index = np.random.randint(0, len(X)-1)\n",
    "new_string = X[start_index]\n",
    "\n",
    "# generating characters\n",
    "for i in range(50):\n",
    "    x = np.reshape(new_string, (1, len(new_string), 1))\n",
    "    x = x / float(len(unique_chars))\n",
    "\n",
    "    #predicting\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    char_out = int_to_char[pred_index]\n",
    "    seq_in = [int_to_char[value] for value in new_string]\n",
    "    print(char_out)\n",
    "\n",
    "    new_string.append(pred_index)\n",
    "    new_string = new_string[1:len(new_string)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
